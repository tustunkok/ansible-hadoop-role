---
- name: Create spark-env file
  copy:
    src: "{{ __spark_installation_dir }}/conf/spark-env.sh.template"
    dest: "{{ __spark_installation_dir }}/conf/spark-env.sh"
    remote_src: true

- name: Create spark-defaults file
  copy:
    src: "{{ __spark_installation_dir }}/conf/spark-defaults.conf.template"
    dest: "{{ __spark_installation_dir }}/conf/spark-defaults.conf"
    remote_src: true

- name: Set HADOOP_CONF_DIR variable in spark-env.sh file
  ansible.builtin.lineinfile:
    path: "{{ __spark_installation_dir }}/conf/spark-env.sh"
    regexp: '^export HADOOP_CONF_DIR='
    line: 'export HADOOP_CONF_DIR={{ __hadoop_installation_dir }}/etc/hadoop'

- name: Set SPARK_DIST_CLASSPATH variable in spark-env.sh file
  ansible.builtin.lineinfile:
    path: "{{ __spark_installation_dir }}/conf/spark-env.sh"
    regexp: '^export SPARK_DIST_CLASSPATH='
    line: 'export SPARK_DIST_CLASSPATH=$({{ __hadoop_installation_dir }}/bin/hadoop classpath)'

- name: Set spark default driver memory variable in spark-defaults.conf file
  ansible.builtin.lineinfile:
    path: "{{ __spark_installation_dir }}/conf/spark-defaults.conf"
    regexp: '^{{ item.conf }}'
    line: '{{ item.conf }} {{ item.value }}'
  loop:
    - { 'conf': 'spark.master', 'value': 'yarn' }
    - { 'conf': 'spark.driver.memory', 'value': '512m' }
    - { 'conf': 'spark.executor.memory  ', 'value': '512m' }
    - { 'conf': 'spark.executor.cores  ', 'value': '1' }
    - { 'conf': 'spark.executor.instances  ', 'value': '1' }
    - { 'conf': 'spark.driver.cores', 'value': '1' }
    - { 'conf': 'spark.deploy.mode', 'value': 'client' }
